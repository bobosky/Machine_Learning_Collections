document.write('<link rel="stylesheet" href="https://assets-cdn.github.com/assets/gist-embed-2c768148c4d27cab10fe818942078e18.css">')
document.write('<div id=\"gist88957433\" class=\"gist\">\n    <div class=\"gist-file\">\n      <div class=\"gist-data\">\n        <div class=\"js-gist-file-update-container js-task-list-container file-box\">\n  <div id=\"file-tokenizer-py\" class=\"file\">\n    \n\n  <div itemprop=\"text\" class=\"blob-wrapper data type-python \">\n      <table class=\"highlight tab-size js-file-line-container\" data-tab-size=\"8\">\n      <tr>\n        <td id=\"file-tokenizer-py-L1\" class=\"blob-num js-line-number\" data-line-number=\"1\"><\/td>\n        <td id=\"file-tokenizer-py-LC1\" class=\"blob-code blob-code-inner js-file-line\"><span class=\"pl-c\"><span class=\"pl-c\">#<\/span> all imports<\/span><\/td>\n      <\/tr>\n      <tr>\n        <td id=\"file-tokenizer-py-L2\" class=\"blob-num js-line-number\" data-line-number=\"2\"><\/td>\n        <td id=\"file-tokenizer-py-LC2\" class=\"blob-code blob-code-inner js-file-line\"><span class=\"pl-k\">from<\/span> collections <span class=\"pl-k\">import<\/span> Counter<\/td>\n      <\/tr>\n      <tr>\n        <td id=\"file-tokenizer-py-L3\" class=\"blob-num js-line-number\" data-line-number=\"3\"><\/td>\n        <td id=\"file-tokenizer-py-LC3\" class=\"blob-code blob-code-inner js-file-line\"><span class=\"pl-k\">import<\/span> spacy<\/td>\n      <\/tr>\n      <tr>\n        <td id=\"file-tokenizer-py-L4\" class=\"blob-num js-line-number\" data-line-number=\"4\"><\/td>\n        <td id=\"file-tokenizer-py-LC4\" class=\"blob-code blob-code-inner js-file-line\"><span class=\"pl-k\">from<\/span> tqdm <span class=\"pl-k\">import<\/span> tqdm, tqdm_notebook, tnrange<\/td>\n      <\/tr>\n      <tr>\n        <td id=\"file-tokenizer-py-L5\" class=\"blob-num js-line-number\" data-line-number=\"5\"><\/td>\n        <td id=\"file-tokenizer-py-LC5\" class=\"blob-code blob-code-inner js-file-line\">tqdm.pandas(<span class=\"pl-v\">desc<\/span><span class=\"pl-k\">=<\/span><span class=\"pl-s\"><span class=\"pl-pds\">&#39;<\/span>Progress<span class=\"pl-pds\">&#39;<\/span><\/span>)<\/td>\n      <\/tr>\n      <tr>\n        <td id=\"file-tokenizer-py-L6\" class=\"blob-num js-line-number\" data-line-number=\"6\"><\/td>\n        <td id=\"file-tokenizer-py-LC6\" class=\"blob-code blob-code-inner js-file-line\">\n<\/td>\n      <\/tr>\n      <tr>\n        <td id=\"file-tokenizer-py-L7\" class=\"blob-num js-line-number\" data-line-number=\"7\"><\/td>\n        <td id=\"file-tokenizer-py-LC7\" class=\"blob-code blob-code-inner js-file-line\"><span class=\"pl-c\"><span class=\"pl-c\">#<\/span> load spacy tokenizer<\/span><\/td>\n      <\/tr>\n      <tr>\n        <td id=\"file-tokenizer-py-L8\" class=\"blob-num js-line-number\" data-line-number=\"8\"><\/td>\n        <td id=\"file-tokenizer-py-LC8\" class=\"blob-code blob-code-inner js-file-line\">nlp <span class=\"pl-k\">=<\/span> spacy.load(<span class=\"pl-s\"><span class=\"pl-pds\">&#39;<\/span>en<span class=\"pl-pds\">&#39;<\/span><\/span>,<span class=\"pl-v\">disable<\/span><span class=\"pl-k\">=<\/span>[<span class=\"pl-s\"><span class=\"pl-pds\">&#39;<\/span>parser<span class=\"pl-pds\">&#39;<\/span><\/span>, <span class=\"pl-s\"><span class=\"pl-pds\">&#39;<\/span>tagger<span class=\"pl-pds\">&#39;<\/span><\/span>, <span class=\"pl-s\"><span class=\"pl-pds\">&#39;<\/span>ner<span class=\"pl-pds\">&#39;<\/span><\/span>])<\/td>\n      <\/tr>\n      <tr>\n        <td id=\"file-tokenizer-py-L9\" class=\"blob-num js-line-number\" data-line-number=\"9\"><\/td>\n        <td id=\"file-tokenizer-py-LC9\" class=\"blob-code blob-code-inner js-file-line\"><span class=\"pl-c\"><span class=\"pl-c\">#<\/span> df.progress_apply is tqdm method for pandas. It shows progress bar for apply function<\/span><\/td>\n      <\/tr>\n      <tr>\n        <td id=\"file-tokenizer-py-L10\" class=\"blob-num js-line-number\" data-line-number=\"10\"><\/td>\n        <td id=\"file-tokenizer-py-LC10\" class=\"blob-code blob-code-inner js-file-line\"><span class=\"pl-c\"><span class=\"pl-c\">#<\/span> remove the leading and trailing spaces<\/span><\/td>\n      <\/tr>\n      <tr>\n        <td id=\"file-tokenizer-py-L11\" class=\"blob-num js-line-number\" data-line-number=\"11\"><\/td>\n        <td id=\"file-tokenizer-py-LC11\" class=\"blob-code blob-code-inner js-file-line\">df[<span class=\"pl-s\"><span class=\"pl-pds\">&#39;<\/span>SentimentText<span class=\"pl-pds\">&#39;<\/span><\/span>] <span class=\"pl-k\">=<\/span> df.SentimentText.progress_apply(<span class=\"pl-k\">lambda<\/span> <span class=\"pl-smi\">x<\/span>: x.strip())<\/td>\n      <\/tr>\n      <tr>\n        <td id=\"file-tokenizer-py-L12\" class=\"blob-num js-line-number\" data-line-number=\"12\"><\/td>\n        <td id=\"file-tokenizer-py-LC12\" class=\"blob-code blob-code-inner js-file-line\">\n<\/td>\n      <\/tr>\n      <tr>\n        <td id=\"file-tokenizer-py-L13\" class=\"blob-num js-line-number\" data-line-number=\"13\"><\/td>\n        <td id=\"file-tokenizer-py-LC13\" class=\"blob-code blob-code-inner js-file-line\"><span class=\"pl-c\"><span class=\"pl-c\">#<\/span> build vocabulary and corresponding counts<\/span><\/td>\n      <\/tr>\n      <tr>\n        <td id=\"file-tokenizer-py-L14\" class=\"blob-num js-line-number\" data-line-number=\"14\"><\/td>\n        <td id=\"file-tokenizer-py-LC14\" class=\"blob-code blob-code-inner js-file-line\">words <span class=\"pl-k\">=<\/span> Counter()<\/td>\n      <\/tr>\n      <tr>\n        <td id=\"file-tokenizer-py-L15\" class=\"blob-num js-line-number\" data-line-number=\"15\"><\/td>\n        <td id=\"file-tokenizer-py-LC15\" class=\"blob-code blob-code-inner js-file-line\"><span class=\"pl-k\">for<\/span> sent <span class=\"pl-k\">in<\/span> tqdm(df.SentimentText.values):<\/td>\n      <\/tr>\n      <tr>\n        <td id=\"file-tokenizer-py-L16\" class=\"blob-num js-line-number\" data-line-number=\"16\"><\/td>\n        <td id=\"file-tokenizer-py-LC16\" class=\"blob-code blob-code-inner js-file-line\">    words.update(w.text.lower() <span class=\"pl-k\">for<\/span> w <span class=\"pl-k\">in<\/span> nlp(sent))<\/td>\n      <\/tr>\n      <tr>\n        <td id=\"file-tokenizer-py-L17\" class=\"blob-num js-line-number\" data-line-number=\"17\"><\/td>\n        <td id=\"file-tokenizer-py-LC17\" class=\"blob-code blob-code-inner js-file-line\">   <\/td>\n      <\/tr>\n      <tr>\n        <td id=\"file-tokenizer-py-L18\" class=\"blob-num js-line-number\" data-line-number=\"18\"><\/td>\n        <td id=\"file-tokenizer-py-LC18\" class=\"blob-code blob-code-inner js-file-line\"><span class=\"pl-c\"><span class=\"pl-c\">#<\/span> sort with most frequently occuring words first<\/span><\/td>\n      <\/tr>\n      <tr>\n        <td id=\"file-tokenizer-py-L19\" class=\"blob-num js-line-number\" data-line-number=\"19\"><\/td>\n        <td id=\"file-tokenizer-py-LC19\" class=\"blob-code blob-code-inner js-file-line\">words <span class=\"pl-k\">=<\/span> <span class=\"pl-c1\">sorted<\/span>(words, <span class=\"pl-v\">key<\/span><span class=\"pl-k\">=<\/span>words.get, <span class=\"pl-v\">reverse<\/span><span class=\"pl-k\">=<\/span><span class=\"pl-c1\">True<\/span>)<\/td>\n      <\/tr>\n      <tr>\n        <td id=\"file-tokenizer-py-L20\" class=\"blob-num js-line-number\" data-line-number=\"20\"><\/td>\n        <td id=\"file-tokenizer-py-LC20\" class=\"blob-code blob-code-inner js-file-line\"><span class=\"pl-c\"><span class=\"pl-c\">#<\/span> add &lt;pad&gt; and &lt;unk&gt; token to vocab which will be used later<\/span><\/td>\n      <\/tr>\n      <tr>\n        <td id=\"file-tokenizer-py-L21\" class=\"blob-num js-line-number\" data-line-number=\"21\"><\/td>\n        <td id=\"file-tokenizer-py-LC21\" class=\"blob-code blob-code-inner js-file-line\">words <span class=\"pl-k\">=<\/span> [<span class=\"pl-s\"><span class=\"pl-pds\">&#39;<\/span>_PAD<span class=\"pl-pds\">&#39;<\/span><\/span>,<span class=\"pl-s\"><span class=\"pl-pds\">&#39;<\/span>_UNK<span class=\"pl-pds\">&#39;<\/span><\/span>] <span class=\"pl-k\">+<\/span> words<\/td>\n      <\/tr>\n      <tr>\n        <td id=\"file-tokenizer-py-L22\" class=\"blob-num js-line-number\" data-line-number=\"22\"><\/td>\n        <td id=\"file-tokenizer-py-LC22\" class=\"blob-code blob-code-inner js-file-line\">\n<\/td>\n      <\/tr>\n      <tr>\n        <td id=\"file-tokenizer-py-L23\" class=\"blob-num js-line-number\" data-line-number=\"23\"><\/td>\n        <td id=\"file-tokenizer-py-LC23\" class=\"blob-code blob-code-inner js-file-line\"><span class=\"pl-c\"><span class=\"pl-c\">#<\/span> create word to index dictionary and reverse<\/span><\/td>\n      <\/tr>\n      <tr>\n        <td id=\"file-tokenizer-py-L24\" class=\"blob-num js-line-number\" data-line-number=\"24\"><\/td>\n        <td id=\"file-tokenizer-py-LC24\" class=\"blob-code blob-code-inner js-file-line\">word2idx <span class=\"pl-k\">=<\/span> {o:i <span class=\"pl-k\">for<\/span> i,o <span class=\"pl-k\">in<\/span> <span class=\"pl-c1\">enumerate<\/span>(words)}<\/td>\n      <\/tr>\n      <tr>\n        <td id=\"file-tokenizer-py-L25\" class=\"blob-num js-line-number\" data-line-number=\"25\"><\/td>\n        <td id=\"file-tokenizer-py-LC25\" class=\"blob-code blob-code-inner js-file-line\">idx2word <span class=\"pl-k\">=<\/span> {i:o <span class=\"pl-k\">for<\/span> i,o <span class=\"pl-k\">in<\/span> <span class=\"pl-c1\">enumerate<\/span>(words)}<\/td>\n      <\/tr>\n      <tr>\n        <td id=\"file-tokenizer-py-L26\" class=\"blob-num js-line-number\" data-line-number=\"26\"><\/td>\n        <td id=\"file-tokenizer-py-LC26\" class=\"blob-code blob-code-inner js-file-line\">\n<\/td>\n      <\/tr>\n      <tr>\n        <td id=\"file-tokenizer-py-L27\" class=\"blob-num js-line-number\" data-line-number=\"27\"><\/td>\n        <td id=\"file-tokenizer-py-LC27\" class=\"blob-code blob-code-inner js-file-line\"><span class=\"pl-k\">def<\/span> <span class=\"pl-en\">indexer<\/span>(<span class=\"pl-smi\">s<\/span>): <\/td>\n      <\/tr>\n      <tr>\n        <td id=\"file-tokenizer-py-L28\" class=\"blob-num js-line-number\" data-line-number=\"28\"><\/td>\n        <td id=\"file-tokenizer-py-LC28\" class=\"blob-code blob-code-inner js-file-line\">  <span class=\"pl-k\">return<\/span> [word2idx[w.text.lower()] <span class=\"pl-k\">for<\/span> w <span class=\"pl-k\">in<\/span> nlp(s)]<\/td>\n      <\/tr>\n      <tr>\n        <td id=\"file-tokenizer-py-L29\" class=\"blob-num js-line-number\" data-line-number=\"29\"><\/td>\n        <td id=\"file-tokenizer-py-LC29\" class=\"blob-code blob-code-inner js-file-line\">\n<\/td>\n      <\/tr>\n      <tr>\n        <td id=\"file-tokenizer-py-L30\" class=\"blob-num js-line-number\" data-line-number=\"30\"><\/td>\n        <td id=\"file-tokenizer-py-LC30\" class=\"blob-code blob-code-inner js-file-line\"><span class=\"pl-c\"><span class=\"pl-c\">#<\/span> tokenize the tweets and calculate lengths<\/span><\/td>\n      <\/tr>\n      <tr>\n        <td id=\"file-tokenizer-py-L31\" class=\"blob-num js-line-number\" data-line-number=\"31\"><\/td>\n        <td id=\"file-tokenizer-py-LC31\" class=\"blob-code blob-code-inner js-file-line\">df[<span class=\"pl-s\"><span class=\"pl-pds\">&#39;<\/span>sentimentidx<span class=\"pl-pds\">&#39;<\/span><\/span>] <span class=\"pl-k\">=<\/span> df.SentimentText.progress_apply(indexer)<\/td>\n      <\/tr>\n      <tr>\n        <td id=\"file-tokenizer-py-L32\" class=\"blob-num js-line-number\" data-line-number=\"32\"><\/td>\n        <td id=\"file-tokenizer-py-LC32\" class=\"blob-code blob-code-inner js-file-line\">df[<span class=\"pl-s\"><span class=\"pl-pds\">&#39;<\/span>lengths<span class=\"pl-pds\">&#39;<\/span><\/span>] <span class=\"pl-k\">=<\/span> df.sentimentidx.progress_apply(<span class=\"pl-c1\">len<\/span>)<\/td>\n      <\/tr>\n      <tr>\n        <td id=\"file-tokenizer-py-L33\" class=\"blob-num js-line-number\" data-line-number=\"33\"><\/td>\n        <td id=\"file-tokenizer-py-LC33\" class=\"blob-code blob-code-inner js-file-line\">\n<\/td>\n      <\/tr>\n      <tr>\n        <td id=\"file-tokenizer-py-L34\" class=\"blob-num js-line-number\" data-line-number=\"34\"><\/td>\n        <td id=\"file-tokenizer-py-LC34\" class=\"blob-code blob-code-inner js-file-line\">fig <span class=\"pl-k\">=<\/span> plt.figure(<span class=\"pl-v\">figsize<\/span><span class=\"pl-k\">=<\/span>(<span class=\"pl-c1\">8<\/span>,<span class=\"pl-c1\">5<\/span>))<\/td>\n      <\/tr>\n      <tr>\n        <td id=\"file-tokenizer-py-L35\" class=\"blob-num js-line-number\" data-line-number=\"35\"><\/td>\n        <td id=\"file-tokenizer-py-LC35\" class=\"blob-code blob-code-inner js-file-line\">ax <span class=\"pl-k\">=<\/span> sns.distplot(df.lengths.values,<span class=\"pl-v\">kde<\/span><span class=\"pl-k\">=<\/span><span class=\"pl-c1\">False<\/span>)<span class=\"pl-bu\">;<\/span><\/td>\n      <\/tr>\n      <tr>\n        <td id=\"file-tokenizer-py-L36\" class=\"blob-num js-line-number\" data-line-number=\"36\"><\/td>\n        <td id=\"file-tokenizer-py-LC36\" class=\"blob-code blob-code-inner js-file-line\">ax.set(<span class=\"pl-v\">xlabel<\/span><span class=\"pl-k\">=<\/span><span class=\"pl-s\"><span class=\"pl-pds\">&#39;<\/span>Tweet Length<span class=\"pl-pds\">&#39;<\/span><\/span>, <span class=\"pl-v\">ylabel<\/span><span class=\"pl-k\">=<\/span><span class=\"pl-s\"><span class=\"pl-pds\">&#39;<\/span>Frequency<span class=\"pl-pds\">&#39;<\/span><\/span>)<\/td>\n      <\/tr>\n<\/table>\n\n\n  <\/div>\n\n  <\/div>\n<\/div>\n\n      <\/div>\n      <div class=\"gist-meta\">\n        <a href=\"https://gist.github.com/hpanwar08/c943e38e4d233d07cf38d1886b487ac2/raw/45634871d164b2e46ed11f92b7186137efd17bf9/tokenizer.py\" style=\"float:right\">view raw<\/a>\n        <a href=\"https://gist.github.com/hpanwar08/c943e38e4d233d07cf38d1886b487ac2#file-tokenizer-py\">tokenizer.py<\/a>\n        hosted with &#10084; by <a href=\"https://github.com\">GitHub<\/a>\n      <\/div>\n    <\/div>\n<\/div>\n')
